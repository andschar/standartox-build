\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage{natbib} % citations
\usepackage{csvsimple}
\usepackage{rotating} % to rotate tables
%% tikz packages
\usepackage{tikz}
\usepackage{forest}
\usetikzlibrary{trees, arrows, shapes.geometric, positioning}
\usepackage{standalone}
%% text packages
\usepackage{siunitx} % fake ° symbol \ang{}
\usepackage[super]{nth} % for 1st, 2nd etc. \nth{}
\usepackage{hyperref}

\newcommand{\etoxbase}{Etox-Base}
\newcommand{\epa}{EPA ECOTOX data base}
\newcommand{\app}{http://139.14.20.252:3838/etox-base-shiny/}
\newcommand{\git}{https://github.com/andreasLD/etox-base}
\newcommand{\gitapp}{https://github.com/andreasLD/etox-base-shiny}
\newcommand{\ecfifty}{EC\textsubscript{50}}


\listfiles


\begin{document}


\title{Etox-Base: A tool to derive exposure endpoints from chemical test results}

\author{Andreas Scharm{\"u}ller\textsuperscript{1{*}},
        Verena Schreiner\textsuperscript{1},
        Ralf B. Sch{\"a}fer\textsuperscript{1}}

\maketitle
\thispagestyle{fancy}

1. Institute of Environmental Sciences, University of Koblenz-Landau Fortstraße 7, 76829 Landau, Germany {*}corresponding author(s):
Andreas Scharm{\"u}ller (scharmueller@uni-landau.de)

\begin{abstract}

this data will be useful for

\end{abstract}

plan:
- occurring in vast numbers
- pathways
- ecosystem services 
- biodiversity loss
- Übergang abschätzung von chemikalien


\section*{Background \& Summary [max 700 words]}

A large number of chemicals such as pharmaceuticals, pesticides and synthetic hormones are in daily use all over the world with insufficient knowledge about possible adverse effects on the environment. In Europe alone some 100,000 chemicals are estimated to be in current use, whereof 30,000 are produced in quantities larger than one ton per year \citep{breithaupt_costs_2006}. Chemicals are brought to the environment deliberately - as it is the case of pesticides, or arrive therein as a byproduct from other processes (e.g. atmospheric emissions or wastewater) \citep{schwarzenbach_challenge_2006}. Ecosystems provide essential services to human societies such as drinking and irrigation water, food and climate regulation. These services are products of different ecosystem functions that crucially depend on the integrity of the populations and communities that drive these ecosystem functions. However, besides habitat degradation, climate change and nutrient enrichment, pollution with man-made chemical toxicants threatens these populations and communities in various ways which are currently not fully understood \citep{steffen_anthropocene_2007}. Pollution with man-made chemical toxicants was indeed identified as one of three major environmental problems for which research gaps hamper the derivation of planetary boundaries, i.e. thresholds beyond which irreversible state shifts may occur \citep{steffen_anthropocene_2007}. Bernhardt et al. \citet{bernhardt_synthetic_2017} argue further that the knowledge gap how chemicals effect populations and communities and hence ecosystem functions and ecosystem services, would also impede society’s ability to accomplish the Sustainable Development Goals of the United Nations. According to Breithaupt \citet{breithaupt_costs_2006} less than one percent of chemicals released to the environment are thoroughly tested. Although for some chemicals advanced and standardized \citep{oecd_oecd_2018} test methods have been developed, ecotoxicological tests for a lot of chemicals, especially newly emerging ones remain scarce and if existent, the information are represented sparsely and in inconsistent formats. \citep{gessner_fostering_2016}. Therefore we developed a tool that collects, processes and aggregates ecotoxicological tests results to then represent them in an harmonized form in a web tool - the \etoxbase tool: \href{http://139.14.20.252:3838/etox-base-shiny/}. 

As a resource for ecotoxicological tests we used the ECOTOXicology knowledgebase (ECOTOX) created by the U.S. Environmental Protection Agency (EPA), which collects raw, non harmonized ecotoxicological test data on on aquatic and terrestrial wildlife as well as plants and publishes it on a quarterly basis. By the time of writing it contained 926,108 test results, comprising 11,685 chemicals tested on 12,668 different species \citep{elonen_ecotoxicology_2018}. The collected ecotoxicological tests contain all sorts of measured endpoints such as Effective Concentrations (\ecfifty{}) values, No-observed effect concentrations (NOEC) or lowest observed effect concentrations (LOEC). Likewise the data set contains different effect measures such as mortality, intoxication and growth as well as test durations ranging from seconds to weeks or even years.

The \etoxbase aggregates this information according to the user's inputs in order to provide reliable concentrations for the derivation of toxicity effect measures such as Species Sensitivity Distributions (SSDs) \citep{posthuma_species_2002} and Toxic Units (TUs), which represent two prominent concepts in ecotoxicology to assess effects on organisms. The former combines toxicity data of several organism groups towards a chemicals to estimate effects on biotic communities, the latter refers to effects of a specific organism (group) towards a chemical. The two concepts are widely used in ecotoxicology \citep{kefford_definition_2011, schafer_effects_2011} since the allow for a comparison of toxicities across multiple chemicals and biological communities, respectively. Although performed on one and the same organism and chemical, outcomes of multiple ecotoxicological tests can vary greatly due to different test parameters, different populations or other individual factors which in turn leads to ambiguities in choosing test results for proper risk assessment.

The \etoxbase tool therefore aggregates test results to obtain single toxicity values for organism, chemical and test duration combinations. The tool downloads every new version of the \epa{} and performs several quality checks, e.g. unit harmonization, and cleaning steps on it. In addition to the test parameters that are retrieved from the \epa{} the tool includes chemical and organism parameters from other open data bases to address missing information such as water solubility, organism habitat or regional occurrence patterns. 

\section*{Methods}

%%The Methods should include detailed text describing any steps or procedures 
%%used in producing the data, including full descriptions of the experimental 
%%design, data acquisition assays, and any computational processing (e.g. 
%%normalization, image feature extraction). Related methods should be grouped 
%%under corresponding subheadings where possible, and methods should be described 
%%in enough detail to allow other researchers to interpret and repeat, if required, 
%%the full study. Specific data outputs should be explicitly referenced via data 
%%citation (see Data Records and Data Citations, below). Authors should cite 
%%previous descriptions of the methods under use, but ideally the method 
%%descriptions should be complete enough for others to understand and reproduce 
%%the methods and processing steps without referring to associated publications. 
%%There is no limit to the length of the Methods section.

The EPA releases \epa{} on a quarterly basis through their website. The software downloads each new version and rebuilds it locally in a PostgreSQL data base. A processing pipeline of several R \citep{r_core_team_r_2017} scripts prepares the data for the tool. The tool itself is a R function that is executed by a user accessing the R shiny \citep{chang_shiny_2018} application. In the following the steps for processing the data are explained in more detail (PATH-TO-OVERVIEW) as well as the scripts that have been used for it (REFER-TO-SCRIPTS-TABLE).

\subsection*{Data acquisition \& preparation}

The data is downloaded (bd\_epa\_download.R) and subsequently built into a PostgreSQL data base (bd\_epa\_postgres.R). Thereafter the data is imported into R for pre-processing (da\_epa1.R, da\_epa2.R, da\_epa3.R), which includes validity checks, removal of special characters, unit harmonizations and selection of relevant variables. At the end the data is stored locally (epa3.rds, epa2\_taxa.rds, epa2\_chem.rds). CAS numbers, unique identifiers and taxon names are then used to query other data bases for additional information on chemicals and biota respectively. Chemical information is retrieved from the Pubchem data base \citep{CITE_PUBCHEM} (qu\_pc.R), from the Compendium of Pesticide Common Names \citep{CITE_AW} (qu\_aw.R), from the Physprop data base \citep{CITE_PHYSPROP} (qu\_pp.R), from EUROSTAT and the Chemspider data base \citep{CITE-CHEMSPIDER}. These queries mostly rely on the webchem R-package \citep{szocs_webchem_2015-1}. For biota, habitat and occurrence information is queried from the World Register of Marine Species (WORMS) \citep{WORMS} and from the Global Biodiversity Information Facility (GBIF) \citep{CITE_RGBIF} using the rgbif R-package. The acquired information is then merged (re\_merge.R), variables are combined and created (re\_combine.R), checked (re\_checks\_internal.R) and finally compiled in one final table (re\_final.R) This table is then used in the application to perform search queries on. For a detailed overview of what information is collected see table \ref{table:processing-scripts}.

\subsection*{The application}
The application is accessible through \etoxbase{} and was built by using the shiny web application framework \citep{chang_shiny_2018} in R. Therein the user can choose to filter the data by several parameters such as chemical class, organism habitat, test duration and test endpoints amongst others. A detailed list for possible filter parameters can be found in \ref{table:meta}. 

In order to be able to calculate TUs and SSDs, derivation of single endpoint values for specific organism groups and a chemicals of the partly extensive test data, the \etoxbase{} aggregates the test results according to the chosen filters in two steps. Firstly the filtered test results are aggregated by the CAS number, the chosen taxon plus the duration and secondly only by the CAS number. The former can't be influenced by the user and calculates either the minimum or the median depending on the amount of results to aggregate (n <= 2: minimum, if n > 2: median). Thereof the second step calculates the minimum, the maximum, the median, the mean or the geometric mean as aggregate. Besides the aggregation some cleaning can also be performed. The \etoxbase{} allows to exclude test results exhibiting concentrations that are higher than the actual water solubility of the respective chemical at \ang{20} C. In any case the user can choose to exclude outliers. The outliers are selected as values that exceed lower (0.25) and the upper (0.75) quartile by 1.5 times the inter-quartile range. All the steps described in this section are executed at each click in the app which runs the function fun\_ec50filter\_aggregation.R (cf. table \ref{table:processing-scripts}). \citep{dowle_data.table_2018}.

\subsection*{Future of the project}
As new versions of the \epa{} is published on a quarterly basis the data acquisition process is automated and new versions of the data and the \app{} are planed to be released regularly.


\begin{figure}
    \includestandalone[width=\textwidth, scale=0.1]{tikz/pipeline_organigram}
    \caption{Organigram}
    \label{fig:organigram}
\end{figure}

\subsection*{Code availability}
%%For all studies using custom code in the generation or processing of datasets, 
%%a statement must be included here, indicating whether and how the code can be 
%%accessed, including any restrictions to access. This section should also include 
%%information on the versions of any software used, if relevant, and any specific 
%%variables or parameters used to generate, test, or process the current dataset. 

The code for processing the data is stored in a Github reopsitory (\git{}). All processing scripts were written in R version 3.4.4. PostgreSQL 9.5 has been used to build the data base. Hence R together with its packages and PostgreSQL suffice to rebuild the process. The \app{} itself is stored in a second Github repostitory (\gitapp{}).

\section*{Data Records}
%%Please explain each data record associated with this work, including
%%the repository where this information is stored, and an overview of
%%the data files and their formats. Each external data record should
%%be listed in Data Citation section at the end of this template, and 
%%records should be cited throughout the manuscript as, for example 
%%(Data Citation 1). 
%%
%%Tables should be used to support the data records, and should clearly indicate 
%%the samples and subjects, their provenance, and the experimental manipulations 
%%performed on each. They should also specify the data output resulting from each 
%%data-collection or analytical step, should these form part of the archived record. 
%%Please see the submission guidelines at the \emph{Scientific Data} website, and 
%%our Word templates for more information on preparing such tables. 

\begin{figure}
    \includestandalone[scale=0.5]{tikz/tree_source}
    \caption{Processing pipeline}
    \label{fig:organigram}
\end{figure}



\section*{Technical Validation}
%%This section presents any experiments or analyses that are needed
%%to support the technical quality of the dataset. This section may
%%be supported by up figures and tables, as needed. This is a required
%%section; authors must present information justifying the reliability
%%of their data.


\section*{Usage Notes}
%%Brief instructions that may help other researchers reuse these dataset.
%%This is an optional section, but strongly encouraged when helpful
%%to readers. This may include discussion of software packages that
%%are suitable for analyzing the assay data files, suggested downstream
%%processing steps (e.g. normalization, etc.), or tips for integrating
%%or comparing this with other datasets. If needed, authors are encouraged
%%to provide code, programs, or data processing workflows when they may help 
%%others analyse the data. We encourage authors to archive related code in 
%%a DOI-issuing archive when possible, but code may also be supplied as 
%%supplementary information files. 
%%
%%For studies involving privacy or safety controls on public access
%%to the data, this section should describe in detail these controls,
%%including how authors can apply to access the data, and what criteria
%%will be used to determine who may access the data, and any limitations
%%on data use.
This data set is designed to support ecotoxicologists in assessing the risk of chemicals on the environment. As there is more and more ecotoxicological test data available, it becomes fundamental to provide such information in reasonable formats. This means, that it should be accessible for humans as well as computers. Up to now ecotoxicoloists rely on effect values of single publications or data bases such as the Pesticide Property Data Base (PPDB), having certain limitations such as encompassing only a few substance groups. The \epa{} tries to fill these gaps by collecting in peer-review articles published ecotoxicological test results. However due to lacking test information and un-harmonized data sets it is not always easily accessible. The \app{} tries to mitigate this gap. An ecotoxicologist can now access the \app{} and retrieve cleaned, harmonized and aggregated test data according to his or her needs.

\subsection*{Limitations}

SSDs aim to extrapolate from species to the community level while not ignoring environmental variables (e.g. pH, temperature, etc.) which can effect the toxicity of a specific chemical greatly \citep{posthuma_species_2002}. For a large number of the \epa{} tests, environmental variables are not recorded (See \ref{table:meta-variables} for proportions of missing entries per variable). Hence to some extent the reported test results inherit uncertainty. In this context we also call for more emphasis on machine-readability when publishing ecotoxicological test results <CITATION ON AS OF HOW MANY DATA POINTS MACHINES ARE NEEDED>. A lot of important information is still confined in continuous text of articles and therefore not ascertainable for large scale analyses.

When using the data from the tool it is essential to think about which endpoint groups (e.g. EC50, LC50, NOEC etc.) and which effect measurements to use (e.g. MOR - Mortality, ITX - Intoxication, GRO - Growth etc.).

Likewise the data of the \epa{} doesn't allow for the in ecotoxicology so frequently used distinction of acute and chronic tests. Even the OECD guidlines are presented only as pdfs inproperly.



discuss flaws in column types (e.g some concentration entries contain '+' or '~' and are therefore not convertable to numeric) - This hampers large scale analysis greatly!


write here that it is meant as an addition to PPDB

in the futrue there will probably more of such resources. Als NORMAN which even performs encompasses expert judgment on the validity of tests

other approaches: https://envirotoxdatabase.org/ - performs no aggregation, not open source



\section*{Acknowledgements}
%%Text acknowledging non-author contributors. Acknowledgements should
%%be brief, and should not include thanks to anonymous referees and
%%editors, or effusive comments. Grant or contribution numbers may be
%%acknowledged. Author contributions Please describe briefly the contributions
%%of each author to this work on a separate line. 
%%
%%AK did this and that. 
%%
%%BG did this and that and the other. 


\section*{Competing financial interests}
%%A competing financial interests statement is required for all accepted
%%papers published in \emph{Scientific Data}. If none exist simply write,
%%``The author(s) declare no competing financial interests''.


\section*{Figures Legends}
%%Figure should be referred to using a consistent numbering scheme through
%%the entire Data Descriptor. For initial submissions, authors may choose
%%to supply this document as a single PDF with embedded figures, but
%%separate figure image files must be provided for revisions and accepted
%%manuscripts. In most cases, a Data Descriptor should not contain more
%%than three figures, but more may be allowed when needed. We discourage
%%the inclusion of figures in the Supplementary Information \textendash{}
%%all key figures should be included here in the main Figure section. 
%%
%%Figure legends begin with a brief title sentence for the whole figure
%%and continue with a short description of what is shown in each panel,
%%as well as explaining any symbols used. Legend must total no more
%%than 350 words, and may contain literature references. 


\section*{Tables}
%%Tables supporting the Data Descriptor. These can provide summary information
%%(sample numbers, demographics, etc.), but they should generally not
%%be used to present primary data (i.e. measurements). Tables containing
%%primary data should be submitted to an appropriate data repository. 
%%
%%Tables may be provided within the \LaTeX{} document or as separate
%%files (tab-delimited text or Excel files). Legends, where needed,
%%should be included here. Generally, a Data Descriptor should have
%%fewer than ten Tables, but more may be allowed when needed. Tables
%%may be of any size, but only Tables which fit onto a single printed
%%page will be included in the PDF version of the article (up to a maximum
%%of three). 

\begin{table}
%\begin{sidewaystable}
    \csvautotabular[respect underscore=true]{data/scripts.csv}
    \caption{R Scripts to query and process data obtained from various resources. The script tree, i.e. the order which script is processed can be found in}
    \label{table:processing-scripts};
%\end{sidewaystable}
\end{table}

\csvreader[tabular=|l|l|,
    table head=\hline & category & description\\\hline,
    late after line=\\\hline]
{data/scripts.csv}{name=\category,surname=\description}
%{\thecsvrow & \surname~\name & \age}



\begin{sidewaystable}
    \csvautotabular[respect all]{data/meta.csv};
    \caption{Meta variables table};
    \label{table:meta-variables};
\end{sidewaystable}




\section*{Figure Legends}

\bibliographystyle{apalike}
\bibliography{refs/references-etox-base}

\section*{not included citations}
Put in citation \citep{hartung_chemical_2009} ? which claims that REACH won't meet their assumptions and say 54 million vertebrate animals are needed for tests that would cost €9.5 billion over the next ten years. I.e 20 times more animals, 6 times the costs in comparison to the official estimates 


\section*{Data Citations}


\end{document}