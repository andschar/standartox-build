%%The Methods should include detailed text describing any steps or procedures 
%%used in producing the data, including full descriptions of the experimental 
%%design, data acquisition assays, and any computational processing (e.g. 
%%normalization, image feature extraction). Related methods should be grouped 
%%under corresponding subheadings where possible, and methods should be described 
%%in enough detail to allow other researchers to interpret and repeat, if required, 
%%the full study. Specific data outputs should be explicitly referenced via data 
%%citation (see Data Records and Data Citations, below). Authors should cite 
%%previous descriptions of the methods under use, but ideally the method 
%%descriptions should be complete enough for others to understand and reproduce 
%%the methods and processing steps without referring to associated publications. 
%%There is no limit to the length of the Methods section.
\section{Methods}
An automated processing pipeline downloads the quarterly released EPA ECOTOX database, performs several preparation steps on it and exports a final Standartox data set. This data set is accessible via a web application (APP) and an application programming interface (API). To facilitate the API access, the R \citep{rcoreteam_language_2017} package \textit{standartox} is built.

\subsection{Processing pipe line}
Standartox downloads the quarterly released EPA ECOTOX data base whenever a new version is published and builds it into a local PostgreSQL data base \citep{szocs_build_2019}. Subsequently Structured Query Language (SQL) functions for further processing the data are developed. In addition lookup tables (Supplement \ref{sup:conv-concentration}, \ref{sup:conv-duration}) that enable duration and concentration unit conversions of the data are created. A meta table providing information such as the release version of the EPA ECOTOX data base is then added. In the next step, Chemical Abstracts Service Numbers (CAS) and International Chemical Identifier (InChI) as well as taxonomic names are used to query additional information from publicly available databases on chemicals and organisms, respectively. This includes the Compendium of Pesticide Common Names \citep{wood_compendium_2019}, the Chemical Entities of Biological Interest (ChEBI) database \citep{hastings_chebi_2016}, the Chemical Identifier Resolver (CIR) service \citep{nationalinstitutesofhealthnih_chemical_2019}, the PHYSPROP database, the Pubchem data base \citep{kim_pubchem_2016}, Eurostat \citep{europeancommission_eurostat_2019} and Wikidata \citep{vrandecic_wikidata_2014} for chemicals and the World Register of Marine Species (WoRMS) \citep{wormseditorialboard_world_2018} and the Global Biodiversity Information Facility (GBIF) \citep{_gbif_2019} (Table \ref{tab:data-base-additional}) for habitat and spatial distribution of organisms. This information is added to Standartox to allow filtering for specific classes of chemicals as well as spatial distribution (i.e. continents) and habitat preferences (e.g. freshwater) of individual taxa.

Taxa that where not identified to at least genus level are excluded.


\input{article/tables/data_base_tables.tex}

Finally, the Standartox data set is compiled, which includes the harmonisation of data, e.g. through conversion of units related to the concentrations and test duration. Out of the unique 1229 concentration units in the EPA ECOTOX data base, Standartox retains only those (n = X) that are unambiguously convertible to one of the following units: $\mu$g/l, g/m2, ppb, mg/kg, \% and flags, the remaining as \textit{other}, resulting in 873473 out of 952625 test results. Furthermore, the units are cleaned, for example through removing additional information in the field such as \textit{food}, \textit{soil}, \textit{ai} that are also coded in other variables and hinder the processing of units. Concentrations that are given as rates such as per day (mg/kg/day) are generally excluded.
Likewise, out of the 125 test duration units in the EPA ECOTOX, Standartox retains only those (n = X) that can be converted to hours, excluding ambiguous duration units such as harvest or lifetime and keeping 905110 out of 952625 test results. Thereby concentration unit additions such as \textit{food}, \textit{soil}, \textit{ai (active ingredient)} etc. are neglected since they are also coded in other variables and only hinder the processing of units. Units such as per day (mg/kg/day) are generally excluded. Test endpoints are restricted to three groups, named NOEX, LOEX and XX50. The former two represent no-observed-adverse-effect and lowest-observed-adverse-effect concentrations or levels, respectively. The latter includes various sub-groups of the half maximal effective concentration, where half of the tested individuals show an effect (e.g. EC50, LC50, LD50), which is a common measure in ecotoxicology \citep{malaj_organic_2014}. Other endpoints, such as Bioconcentration factors (BCF), non-half maximal effective concentrations (e.g. IC10, EC25, LD99) or maximum acceptable toxicant (MATC) concentrations are removed. Beyond that, filters for the CAS number, the concentration type (e.g. active ingredient, formulation), the chemical class (e.g. fungicides, metals), taxon, organism habitat (e.g freshwater, terrestrial) and region (e.g. Europe, Asia), test duration as well as effect type (e.g. mortality, growth) are created. In order to detect possible outliers among the test results, we flag values that exceed 1.5 times the interquartile range (IQR) within groups with identical test parameters (e.g. chemical, taxon, duraiton). Along with the compiled Standartox data set, a catalog, listing all distinct entries and value ranges, for categorical and continuous variables, respectively is created. Finally, we run quality control scripts that check the accuracy of the data. Single processing scripts are listed in Figure \ref{fig:pipeline-tree}. The final Standartox table together with the catalog is exported and accessible via web application and the API.

\begin{figure}
    \includestandalone[scale=0.5]{article/tikz/pipeline-organigram}
    %\input[scale = 0.5]{article/tikz/pipeline-organigram.tex}
    \caption{Organigram of Standartox.}
    \label{fig:stx-organigram}
\end{figure}

\subsection{Web application (APP) and Application Programming Interface (API)}
The web application (APP) and the Application Programming Interface (API) load the compressed serialized Standartox data into memory and allow a client to interact with it. The client can then call the functions stx\_filter() and stx\_aggregate() that filter and aggregate the data according to specific parameters (Table \ref{tab:app-parameters}).

\subsubsection{Web application (APP)}
The interactive APP was built in R using the shiny web application framework, which runs with the help of a shiny server \citep{chang_shiny_2018} on \url{standartox.uni-landau.de}. It is a set of R functions that allow a user to filter, aggregate and download the data.

\subsubsection{Application programming interface (API)}
The API is built by using the R package plumber \citep{trestletechnologyllc_plumber_2018}, which allows for the creation of RESTful APIs from R. The API is reachable via the URL \url{http://139.14.20.252} and port 8000. Four API-endpoints (\textit{/catalog}, \textit{/filter}, \textit{/aggregate} and \textit{/meta}) can be queried from the client side. The \textit{/catalog} API-endpoint returns a JavaScript Object Notation (JSON) file containing a catalog of possible filter parameters to choose from. The \textit{/filter} returns the filtered Standartox table as a compressed serialized binary file created by the R fst package \citep{klik_fst_2019}, to reduce size and allow for fast user queries. The \textit{/aggregate} API-endpoint returns an R function allowing the client to aggregate the filtered data. Lastly, the \textit{/meta} API-endpoint returns a JSON file with meta information, such as the timestamp of the request and the used Standartox version. The API is designed to be used with the R-package standartox and therefore uses serialization methods specific to R (rds() from the R package base and fst() from the package fst).

\subsubsection{R-package}
The R-package standartox accesses the API through two functions \textit{stx\_catalog()} and \textit{stx\_query()}. The former accesses the \textit{/catalog} API-endpoint and returns a R list object of possible filter parameters (Table \ref{tab:app-parameters}) that can be used in \textit{stx\_query()}. The latter returns a R list of three tables (i.e. R data.frames) containing the filtered data set, the aggregated data set and a table with the meta information retrieved from the API endpoints \textit{/filter} and \textit{/meta}.

\subsection{Technical Validity}
To guarantee appropriate unit conversion and harmonisation, we compare for each of the 1229 distinct concentration and for each of the 129 duration units the automatically converted units to one manually calculated one.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TODO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Where to put?
(See Table \ref{tab:app-parameters})




\iffalse
- Endpoint: For the last parameter here, only be exclusive. 

TODO: How does this fit?
\begin{table}
    \input{article/tables/data_refinement_counts.tex}
    \caption{Reduction of data in the compilation process for Standartox}
    \label{tab:data-refinement}
\end{table}

\fi


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OLD %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\textbf{OLD: Standartox aggregates the test results according to chosen filters in a two step process. Firstly the filtered test results are aggregated by the CAS number, the chosen taxon and the selected test duration. Secondly, the returned data is then aggregated by the CAS number. The former can't be influenced by the user and calculates either the minimum or the median depending on the amount of results to aggregate (n <= 2: minimum, if n > 2: median). Thereof the second step calculates the minimum, the maximum, the median, the geometric mean, or the arithmetic mean as an aggregate.}
\fi


